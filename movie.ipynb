{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a67984e3",
      "metadata": {
        "id": "a67984e3",
        "outputId": "f1dc1595-7d6e-4a8b-f5ee-ff53afb0d26e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.6/152.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.36 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.10.19 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 12.0.1 which is incompatible.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
            "langchain 0.3.4 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.19 which is incompatible.\n",
            "langchain-core 0.3.13 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.19 which is incompatible.\n",
            "langchain-core 0.3.13 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "openai 1.52.2 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.23.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pylibcudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 12.0.1 which is incompatible.\n",
            "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.3 which is incompatible.\n",
            "torch 2.5.0+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "typeguard 4.4.0 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# расскоментируйте код ниже, чтобы установить все зависимости\n",
        "!pip install -q \\\n",
        "    pyarrow==12.0.1 \\\n",
        "    polars==0.18.6 \\\n",
        "    tqdm==4.65.0 \\\n",
        "    scipy==1.10.1 \\\n",
        "    scikit-learn==1.3.0 \\\n",
        "    numpy==1.24.3 \\\n",
        "    qdrant-client==1.3.1 \\\n",
        "    faiss-cpu==1.7.4 \\\n",
        "    redis==4.6.0 \\\n",
        "    implicit==0.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "17e95fce",
      "metadata": {
        "id": "17e95fce"
      },
      "outputs": [],
      "source": [
        "# раскоментируйте код ниже, чтобы скачать данные\n",
        "!wget -q https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip -q ml-100k.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c48c874e",
      "metadata": {
        "id": "c48c874e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "\n",
        "import scipy.sparse as sp\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import random\n",
        "from typing import List, Any\n",
        "\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams, PointStruct"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "p32lX8I7Xxtr"
      },
      "id": "p32lX8I7Xxtr",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8UTh8MOeQ-5e"
      },
      "id": "8UTh8MOeQ-5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном коде рейтинги пользователей фильмов преобразуются в бинарные метки (0 или 1), где 1 обозначает, что фильм понравился пользователю (рейтинг 5), а 0 — что фильм не понравился (рейтинг не равен 5). Такое преобразование имеет несколько обоснований:\n",
        "\n",
        "1. **Упрощение задачи:** Задача предсказания рейтингов (от 1 до 5) является задачей регрессии, которая может быть сложнее, чем задача бинарной классификации. Преобразование в бинарную задачу упрощает процесс моделирования и позволяет использовать более простые алгоритмы машинного обучения.\n",
        "\n",
        "2. **Учет только явного интереса:** Цель системы рекомендаций — предсказать, понравится ли пользователю фильм. Рейтинг 5 наиболее явно демонстрирует интерес пользователя к фильму.  Используя только информацию о том, понравился ли фильм или нет, мы фокусируемся на этой ключевой информации, игнорируя нюансы, которые могут быть менее важны для рекомендательной системы.\n",
        "\n",
        "3. **Соответствие бизнес-цели:** В контексте рекомендательных систем, часто важнее всего определить, будет ли пользователь взаимодействовать с контентом (в данном случае, поставить фильму оценку 5). Это может быть связано с увеличением вовлеченности пользователей или увеличением доходов от просмотров рекламы.\n",
        "\n",
        "4. **Повышение эффективности модели:** Использование бинарной классификации может привести к более эффективной модели, которая быстрее обучается и предсказывает результаты с высокой точностью.\n",
        "\n",
        "Таким образом, преобразование рейтингов в бинарные метки (liked) является целесообразным шагом для упрощения задачи, повышения эффективности модели и фокусировки на ключевой информации, которая важна для рекомендательной системы.\n"
      ],
      "metadata": {
        "id": "E6Ufo9Lxhqgn"
      },
      "id": "E6Ufo9Lxhqgn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MovieLens датасет**\n",
        "\n",
        "В качестве данных будем использовать датасет с оценками к фильмам Movielens-100k. В нем есть поле ratings\n"
      ],
      "metadata": {
        "id": "bzPo5a1Yl3ep"
      },
      "id": "bzPo5a1Yl3ep"
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных о фильмах и оценках пользователей\n",
        "ratings = pl.read_csv(\n",
        "    'ml-100k/u.data',\n",
        "    separator='\\t',\n",
        "    has_header=False,\n",
        "    new_columns=['user_id', 'movie_id', 'rating', 'timestamp']\n",
        ")\n",
        "\n",
        "# Создаем бинарный таргет: 5 - нравится, остальное - нет\n",
        "ratings = ratings.with_columns([\n",
        "    pl.when(pl.col('rating') == 5).then(1).otherwise(0).alias('liked')\n",
        "])\n",
        "print(ratings.head())\n",
        "rating_mul = ratings['rating']\n",
        "ratings = ratings.select(['user_id', 'movie_id', 'liked', 'timestamp'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AlWE_rAQ40c",
        "outputId": "8814054e-0e62-4bce-80e8-0c21912f7226"
      },
      "id": "5AlWE_rAQ40c",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (5, 5)\n",
            "┌─────────┬──────────┬────────┬───────────┬───────┐\n",
            "│ user_id ┆ movie_id ┆ rating ┆ timestamp ┆ liked │\n",
            "│ ---     ┆ ---      ┆ ---    ┆ ---       ┆ ---   │\n",
            "│ i64     ┆ i64      ┆ i64    ┆ i64       ┆ i32   │\n",
            "╞═════════╪══════════╪════════╪═══════════╪═══════╡\n",
            "│ 196     ┆ 242      ┆ 3      ┆ 881250949 ┆ 0     │\n",
            "│ 186     ┆ 302      ┆ 3      ┆ 891717742 ┆ 0     │\n",
            "│ 22      ┆ 377      ┆ 1      ┆ 878887116 ┆ 0     │\n",
            "│ 244     ┆ 51       ┆ 2      ┆ 880606923 ┆ 0     │\n",
            "│ 166     ┆ 346      ┆ 1      ┆ 886397596 ┆ 0     │\n",
            "└─────────┴──────────┴────────┴───────────┴───────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных о фильмах\n",
        "movies_file = \"ml-100k/u.item\"\n",
        "movie_columns = [\"movie_id\", \"movie_title\", \"release_date\", \"video_release_date\", \"IMDb_URL\"] + [f\"genre_{i}\" for i in range(19)]\n",
        "movies_pd = pd.read_csv(movies_file, sep=\"|\", header=None, names=movie_columns, encoding=\"cp1251\")\n",
        "\n",
        "# Конвертация в Polars DataFrame\n",
        "\n",
        "movies = pl.DataFrame(movies_pd)\n",
        "movies.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "njwCzA-iuiR_",
        "outputId": "c234225c-c464-40cf-d1d0-a96b7537bc87"
      },
      "id": "njwCzA-iuiR_",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 24)\n",
              "┌──────────┬───────────┬────────────┬──────────────┬───┬──────────┬──────────┬──────────┬──────────┐\n",
              "│ movie_id ┆ movie_tit ┆ release_da ┆ video_releas ┆ … ┆ genre_15 ┆ genre_16 ┆ genre_17 ┆ genre_18 │\n",
              "│ ---      ┆ le        ┆ te         ┆ e_date       ┆   ┆ ---      ┆ ---      ┆ ---      ┆ ---      │\n",
              "│ i64      ┆ ---       ┆ ---        ┆ ---          ┆   ┆ i64      ┆ i64      ┆ i64      ┆ i64      │\n",
              "│          ┆ str       ┆ str        ┆ f64          ┆   ┆          ┆          ┆          ┆          │\n",
              "╞══════════╪═══════════╪════════════╪══════════════╪═══╪══════════╪══════════╪══════════╪══════════╡\n",
              "│ 1        ┆ Toy Story ┆ 01-Jan-199 ┆ null         ┆ … ┆ 0        ┆ 0        ┆ 0        ┆ 0        │\n",
              "│          ┆ (1995)    ┆ 5          ┆              ┆   ┆          ┆          ┆          ┆          │\n",
              "│ 2        ┆ GoldenEye ┆ 01-Jan-199 ┆ null         ┆ … ┆ 0        ┆ 1        ┆ 0        ┆ 0        │\n",
              "│          ┆ (1995)    ┆ 5          ┆              ┆   ┆          ┆          ┆          ┆          │\n",
              "│ 3        ┆ Four      ┆ 01-Jan-199 ┆ null         ┆ … ┆ 0        ┆ 1        ┆ 0        ┆ 0        │\n",
              "│          ┆ Rooms     ┆ 5          ┆              ┆   ┆          ┆          ┆          ┆          │\n",
              "│          ┆ (1995)    ┆            ┆              ┆   ┆          ┆          ┆          ┆          │\n",
              "│ 4        ┆ Get       ┆ 01-Jan-199 ┆ null         ┆ … ┆ 0        ┆ 0        ┆ 0        ┆ 0        │\n",
              "│          ┆ Shorty    ┆ 5          ┆              ┆   ┆          ┆          ┆          ┆          │\n",
              "│          ┆ (1995)    ┆            ┆              ┆   ┆          ┆          ┆          ┆          │\n",
              "│ 5        ┆ Copycat   ┆ 01-Jan-199 ┆ null         ┆ … ┆ 0        ┆ 1        ┆ 0        ┆ 0        │\n",
              "│          ┆ (1995)    ┆ 5          ┆              ┆   ┆          ┆          ┆          ┆          │\n",
              "└──────────┴───────────┴────────────┴──────────────┴───┴──────────┴──────────┴──────────┴──────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 24)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movie_id</th><th>movie_title</th><th>release_date</th><th>video_release_date</th><th>IMDb_URL</th><th>genre_0</th><th>genre_1</th><th>genre_2</th><th>genre_3</th><th>genre_4</th><th>genre_5</th><th>genre_6</th><th>genre_7</th><th>genre_8</th><th>genre_9</th><th>genre_10</th><th>genre_11</th><th>genre_12</th><th>genre_13</th><th>genre_14</th><th>genre_15</th><th>genre_16</th><th>genre_17</th><th>genre_18</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>&quot;Toy Story (199…</td><td>&quot;01-Jan-1995&quot;</td><td>null</td><td>&quot;http://us.imdb…</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>2</td><td>&quot;GoldenEye (199…</td><td>&quot;01-Jan-1995&quot;</td><td>null</td><td>&quot;http://us.imdb…</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>3</td><td>&quot;Four Rooms (19…</td><td>&quot;01-Jan-1995&quot;</td><td>null</td><td>&quot;http://us.imdb…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>4</td><td>&quot;Get Shorty (19…</td><td>&quot;01-Jan-1995&quot;</td><td>null</td><td>&quot;http://us.imdb…</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>5</td><td>&quot;Copycat (1995)…</td><td>&quot;01-Jan-1995&quot;</td><td>null</td><td>&quot;http://us.imdb…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies = movies.with_columns([\n",
        "    pl.Series(\"movie_title\", movies_pd[\"movie_title\"]),\n",
        "    pl.Series(\"video_release_date\", movies_pd[\"video_release_date\"]),\n",
        "    pl.Series(\"IMDb_URL\", movies_pd[\"IMDb_URL\"]),\n",
        "])\n",
        "\n",
        "movies = movies.select(['movie_id', 'release_date','movie_title', 'video_release_date', 'IMDb_URL'] + [f\"genre_{i}\" for i in range(19)])\n",
        "\n",
        "# Объединяем данные рейтингов и фильмов по movie_id\n",
        "ratings_with_titles = ratings.join(movies, on=\"movie_id\")\n",
        "ratings_with_titles.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "3btlsjyyeHMu",
        "outputId": "24c6d8d7-7d2c-4bf0-b6c8-e6421338d0de"
      },
      "id": "3btlsjyyeHMu",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 27)\n",
              "┌─────────┬──────────┬───────┬───────────┬───┬──────────┬──────────┬──────────┬──────────┐\n",
              "│ user_id ┆ movie_id ┆ liked ┆ timestamp ┆ … ┆ genre_15 ┆ genre_16 ┆ genre_17 ┆ genre_18 │\n",
              "│ ---     ┆ ---      ┆ ---   ┆ ---       ┆   ┆ ---      ┆ ---      ┆ ---      ┆ ---      │\n",
              "│ i64     ┆ i64      ┆ i32   ┆ i64       ┆   ┆ i64      ┆ i64      ┆ i64      ┆ i64      │\n",
              "╞═════════╪══════════╪═══════╪═══════════╪═══╪══════════╪══════════╪══════════╪══════════╡\n",
              "│ 196     ┆ 242      ┆ 0     ┆ 881250949 ┆ … ┆ 0        ┆ 0        ┆ 0        ┆ 0        │\n",
              "│ 186     ┆ 302      ┆ 0     ┆ 891717742 ┆ … ┆ 0        ┆ 1        ┆ 0        ┆ 0        │\n",
              "│ 22      ┆ 377      ┆ 0     ┆ 878887116 ┆ … ┆ 0        ┆ 0        ┆ 0        ┆ 0        │\n",
              "│ 244     ┆ 51       ┆ 0     ┆ 880606923 ┆ … ┆ 0        ┆ 0        ┆ 1        ┆ 1        │\n",
              "│ 166     ┆ 346      ┆ 0     ┆ 886397596 ┆ … ┆ 0        ┆ 0        ┆ 0        ┆ 0        │\n",
              "└─────────┴──────────┴───────┴───────────┴───┴──────────┴──────────┴──────────┴──────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 27)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>movie_id</th><th>liked</th><th>timestamp</th><th>release_date</th><th>movie_title</th><th>video_release_date</th><th>IMDb_URL</th><th>genre_0</th><th>genre_1</th><th>genre_2</th><th>genre_3</th><th>genre_4</th><th>genre_5</th><th>genre_6</th><th>genre_7</th><th>genre_8</th><th>genre_9</th><th>genre_10</th><th>genre_11</th><th>genre_12</th><th>genre_13</th><th>genre_14</th><th>genre_15</th><th>genre_16</th><th>genre_17</th><th>genre_18</th></tr><tr><td>i64</td><td>i64</td><td>i32</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>196</td><td>242</td><td>0</td><td>881250949</td><td>&quot;24-Jan-1997&quot;</td><td>&quot;Kolya (1996)&quot;</td><td>null</td><td>&quot;http://us.imdb…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>186</td><td>302</td><td>0</td><td>891717742</td><td>&quot;01-Jan-1997&quot;</td><td>&quot;L.A. Confident…</td><td>null</td><td>&quot;http://us.imdb…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>22</td><td>377</td><td>0</td><td>878887116</td><td>&quot;01-Jan-1994&quot;</td><td>&quot;Heavyweights (…</td><td>null</td><td>&quot;http://us.imdb…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>244</td><td>51</td><td>0</td><td>880606923</td><td>&quot;01-Jan-1994&quot;</td><td>&quot;Legends of the…</td><td>null</td><td>&quot;http://us.imdb…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td></tr><tr><td>166</td><td>346</td><td>0</td><td>886397596</td><td>&quot;01-Jan-1997&quot;</td><td>&quot;Jackie Brown (…</td><td>null</td><td>&quot;http://us.imdb…</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ratings_with_titles = ratings_with_titles.to_pandas()\n",
        "\n",
        "# Преобразуем дату выпуска в числовой год\n",
        "ratings_with_titles['release_year'] = pd.to_datetime(ratings_with_titles['release_date'], errors='coerce').dt.year\n",
        "ratings_with_titles = ratings_with_titles.fillna(0)\n"
      ],
      "metadata": {
        "id": "7_6C6NdSvE9j"
      },
      "id": "7_6C6NdSvE9j",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Достаточно данных для обучения: при 70% обучающих данных модель получает\n",
        "достаточно примеров, чтобы \"научиться\" распознавать закономерности и особенности в данных. Это особенно важно для рекомендационных систем, где необходимо понимать, какие фильмы пользователи предпочитают.\n",
        "\n",
        "2. Достаточный объем тестовых данных: 30% оставленных для теста дают модели достаточно новых примеров, чтобы объективно оценить её способность обобщать, т.е. делать точные предсказания на данных, с которыми она ранее не сталкивалась.\n",
        "\n",
        "3. Избежание переобучения и недообучения: 70/30 - это баланс, при котором уменьшается риск переобучения (overfitting), когда модель слишком точно подстраивается под обучающие данные, и недообучения (underfitting), когда данных для обучения недостаточно для выявления закономерностей.\n",
        "\n",
        "Оптимальный баланс для небольших датасетов: для относительно небольшого набора данных, как MovieLens 100K, 70/30 считается оптимальным, поскольку сохраняется достаточно данных для тестирования, чтобы оценить, как модель будет работать в реальных условиях.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "15Jy_TWOxHEN"
      },
      "id": "15Jy_TWOxHEN"
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка признаков и целевой переменной\n",
        "X = ratings_with_titles.drop(columns=['liked', 'release_date', 'movie_title', 'video_release_date', 'IMDb_URL'])\n",
        "y = ratings_with_titles['liked']\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки с балансировкой классов\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Преобразуем DataFrame в массивы для обеих выборок\n",
        "X_train_np = X_train.to_numpy()\n",
        "X_test_np = X_test.to_numpy()"
      ],
      "metadata": {
        "id": "ZUL41hi3u7Wz"
      },
      "id": "ZUL41hi3u7Wz",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylxkwg_d_3R3",
        "outputId": "f1a4119a-4405-45e2-d64e-12c597eb701f"
      },
      "id": "ylxkwg_d_3R3",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 23)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxmltools\n",
        "!pip install onnxconverter-common\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "_R1iNMz2A3kM",
        "outputId": "f6f729f4-0aac-4f3f-e63d-969612352c5a"
      },
      "id": "_R1iNMz2A3kM",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxmltools in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxmltools) (1.24.3)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnxmltools) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnxmltools) (5.28.3)\n",
            "Collecting onnxconverter-common\n",
            "  Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnxconverter-common) (1.24.3)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnxconverter-common) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxconverter-common) (24.1)\n",
            "Collecting protobuf==3.20.2 (from onnxconverter-common)\n",
            "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Downloading onnxconverter_common-1.14.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, onnxconverter-common\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.28.3\n",
            "    Uninstalling protobuf-5.28.3:\n",
            "      Successfully uninstalled protobuf-5.28.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-tools 1.67.1 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed onnxconverter-common-1.14.0 protobuf-3.20.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "03a5db042dfb4700ae5e8980473c842d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skl2onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChcMDPjzCjgc",
        "outputId": "ed114059-c543-46c4-811c-b1b81a23d3d5"
      },
      "id": "ChcMDPjzCjgc",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skl2onnx\n",
            "  Downloading skl2onnx-1.17.0-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: onnx>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from skl2onnx) (1.17.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.10/dist-packages (from skl2onnx) (1.3.0)\n",
            "Requirement already satisfied: onnxconverter-common>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from skl2onnx) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.2.1->skl2onnx) (1.24.3)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.2.1->skl2onnx) (3.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxconverter-common>=1.7.0->skl2onnx) (24.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->skl2onnx) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.1->skl2onnx) (3.5.0)\n",
            "Downloading skl2onnx-1.17.0-py2.py3-none-any.whl (298 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/298.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.4/298.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: skl2onnx\n",
            "Successfully installed skl2onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import skl2onnx\n",
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "import onnx\n",
        "\n",
        "# Установка initial_type для данных с 23 признаками\n",
        "initial_type = [('input', FloatTensorType([None, 23]))]\n",
        "\n",
        "\n",
        "print(\"Модель XGBoost успешно сконвертирована в формат ONNX и сохранена как xgboost_model.onnx\")\n",
        "# Алгоритмы для модели\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
        "    \"XG Boost\": XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# Оценка моделей по различным метрикам\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train_np[:, 2:], y_train)\n",
        "    y_pred = model.predict(X_test_np[:, 2:])\n",
        "    # Метрики\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    if model_name!=\"XG Boost\":\n",
        "        onnx_model = convert_sklearn(model, initial_types=initial_type)\n",
        "\n",
        "        # Сохраняем в файл\n",
        "        with open(f\"{model_name}.onnx\", \"wb\") as f:\n",
        "              f.write(onnx_model.SerializeToString())\n",
        "    print(f\"\\n\")\n",
        "    print(f\"{model_name}:\\n\")\n",
        "    print(\"  Accuracy:\", accuracy)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"  ROC AUC:\", roc_auc)\n",
        "    print(\"  Confusion Matrix:\\n\", conf_matrix)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wDuwok_15Gc",
        "outputId": "b8d4d688-965d-4e2b-e33a-0ce1a6d8ae3c"
      },
      "id": "4wDuwok_15Gc",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель XGBoost успешно сконвертирована в формат ONNX и сохранена как xgboost_model.onnx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Logistic Regression:\n",
            "\n",
            "  Accuracy: 0.7880666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      1.00      0.88     23642\n",
            "           1       0.00      0.00      0.00      6358\n",
            "\n",
            "    accuracy                           0.79     30000\n",
            "   macro avg       0.39      0.50      0.44     30000\n",
            "weighted avg       0.62      0.79      0.69     30000\n",
            "\n",
            "  ROC AUC: 0.5\n",
            "  Confusion Matrix:\n",
            " [[23642     0]\n",
            " [ 6358     0]]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Decision Tree:\n",
            "\n",
            "  Accuracy: 0.7152333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82     23642\n",
            "           1       0.33      0.33      0.33      6358\n",
            "\n",
            "    accuracy                           0.72     30000\n",
            "   macro avg       0.57      0.57      0.57     30000\n",
            "weighted avg       0.72      0.72      0.72     30000\n",
            "\n",
            "  ROC AUC: 0.5740062211409315\n",
            "  Confusion Matrix:\n",
            " [[19366  4276]\n",
            " [ 4267  2091]]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Random Forest:\n",
            "\n",
            "  Accuracy: 0.7896\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.99      0.88     23642\n",
            "           1       0.57      0.03      0.06      6358\n",
            "\n",
            "    accuracy                           0.79     30000\n",
            "   macro avg       0.68      0.51      0.47     30000\n",
            "weighted avg       0.75      0.79      0.71     30000\n",
            "\n",
            "  ROC AUC: 0.5116664088539548\n",
            "  Confusion Matrix:\n",
            " [[23502   140]\n",
            " [ 6172   186]]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "XG Boost:\n",
            "\n",
            "  Accuracy: 0.7926333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.99      0.88     23642\n",
            "           1       0.61      0.06      0.11      6358\n",
            "\n",
            "    accuracy                           0.79     30000\n",
            "   macro avg       0.70      0.52      0.50     30000\n",
            "weighted avg       0.76      0.79      0.72     30000\n",
            "\n",
            "  ROC AUC: 0.5243994984001552\n",
            "  Confusion Matrix:\n",
            " [[23405   237]\n",
            " [ 5984   374]]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WX-x1H_qCgzP"
      },
      "id": "WX-x1H_qCgzP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Логистическая регрессия:**\n",
        "\n",
        "1. Линейная модель: логистическая регрессия является простой и интерпретируемой моделью, что позволяет быстро оценить основные закономерности в данных.\n",
        "2. Быстрота обучения: она обучается быстро, что полезно при быстрой оценке базовой производительности на новом наборе данных.\n",
        "3. Понимание вероятностей: метод возвращает вероятности принадлежности к классам, что полезно для рекомендаций, так как можно интерпретировать вероятность как степень уверенности."
      ],
      "metadata": {
        "id": "HZIDKrruzd50"
      },
      "id": "HZIDKrruzd50"
    },
    {
      "cell_type": "code",
      "source": [
        "# Логистическая регрессия\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train_np[:, 2:], y_train)\n",
        "y_pred_log = log_reg.predict(X_test_np[:, 2:])\n",
        "y_prob_log = log_reg.predict_proba(X_test_np[:, 2:])[:, 1]\n",
        "\n",
        "\n",
        "\n",
        "# 4. Оценка моделей\n",
        "print(\"Logistic Regression\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log)}\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, y_prob_log)}\")\n",
        "print(classification_report(y_test, y_pred_log))"
      ],
      "metadata": {
        "id": "F4cR9CGAaT5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01bea809-c7b7-491e-d13a-9d01ef23b0f7"
      },
      "id": "F4cR9CGAaT5T",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "Accuracy: 0.7880666666666667\n",
            "ROC AUC: 0.4956663681130709\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      1.00      0.88     23642\n",
            "           1       0.00      0.00      0.00      6358\n",
            "\n",
            "    accuracy                           0.79     30000\n",
            "   macro avg       0.39      0.50      0.44     30000\n",
            "weighted avg       0.62      0.79      0.69     30000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Случайный лес:\n",
        "\n",
        "1. Мощный ансамблевый метод: случайный лес объединяет множество деревьев, что повышает устойчивость модели и ее способность обобщать.\n",
        "2. Повышенная точность: он обычно показывает высокую точность по сравнению с одиночными деревьями благодаря уменьшению вариативности.\n",
        "3. Контроль глубины: ограничение глубины max_depth=10 позволяет получить сбалансированный результат, избегая избыточного подстраивания."
      ],
      "metadata": {
        "id": "NqQ1X-mXz7qt"
      },
      "id": "NqQ1X-mXz7qt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Случайный лес\n",
        "forest = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "forest.fit(X_train_np[:, 2:], y_train)\n",
        "y_pred_forest = forest.predict(X_test_np[:, 2:])\n",
        "y_prob_forest = forest.predict_proba(X_test_np[:, 2:])[:, 1]\n",
        "\n",
        "print(\"\\nRandom Forest\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_forest)}\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, y_prob_forest)}\")\n",
        "print(classification_report(y_test, y_pred_forest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqVrp8oYzN2V",
        "outputId": "b9f6c6bf-bbb2-43fc-e308-dc2be0fd240a"
      },
      "id": "lqVrp8oYzN2V",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest\n",
            "Accuracy: 0.7896\n",
            "ROC AUC: 0.6812653624864915\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.99      0.88     23642\n",
            "           1       0.57      0.03      0.06      6358\n",
            "\n",
            "    accuracy                           0.79     30000\n",
            "   macro avg       0.68      0.51      0.47     30000\n",
            "weighted avg       0.75      0.79      0.71     30000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Дерево решений:**\n",
        "\n",
        "1. Интерпретируемость: дерево решений строит иерархию правил для принятия решений, что делает его легко интерпретируемым. Для рекомендации фильмов полезно понимать, по каким \"правилам\" система принимает решения.\n",
        "2. Работа с категориальными признаками: деревья хорошо обрабатывают категориальные признаки и помогают при неявных нелинейных зависимостях.\n",
        "3. Регулирование глубины: максимальная глубина max_depth=5 и минимальное количество образцов min_samples_leaf=10 предотвращают переобучение, особенно для небольшого набора данных, как MovieLens 100K."
      ],
      "metadata": {
        "id": "bxJsuPKuzwa6"
      },
      "id": "bxJsuPKuzwa6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Дерево решений\n",
        "tree = DecisionTreeClassifier(max_depth=5, min_samples_leaf=10, random_state=42)\n",
        "tree.fit(X_train_np[:, 2:], y_train)\n",
        "y_pred_tree = tree.predict(X_test_np[:, 2:])\n",
        "y_prob_tree = tree.predict_proba(X_test_np[:, 2:])[:, 1]\n",
        "\n",
        "onnx_model = convert_sklearn(tree, initial_types=initial_type)\n",
        "\n",
        "# Сохраняем в файл\n",
        "with open(\"DecisionTree.onnx\", \"wb\") as f:\n",
        "      f.write(onnx_model.SerializeToString())\n",
        "print(\"\\nDecision Tree\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_tree)}\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, y_prob_tree)}\")\n",
        "print(classification_report(y_test, y_pred_tree))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb2UUm6kzEo_",
        "outputId": "d684511d-611b-40c6-a9e2-93a386ab630f"
      },
      "id": "Gb2UUm6kzEo_",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree\n",
            "Accuracy: 0.7906666666666666\n",
            "ROC AUC: 0.6343869650566957\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.99      0.88     23642\n",
            "           1       0.56      0.05      0.10      6358\n",
            "\n",
            "    accuracy                           0.79     30000\n",
            "   macro avg       0.68      0.52      0.49     30000\n",
            "weighted avg       0.75      0.79      0.72     30000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Обоснование выбора метрик:**\n",
        "1. Accuracy - общая точность модели.\n",
        "2. Precision - доля правильно предсказанных положительных случаев среди всех предсказанных положительных.\n",
        "3. Recall - доля правильно предсказанных положительных случаев среди всех фактических положительных.\n",
        "4. F1-score - среднее гармоническое precision и recall.\n",
        "\n",
        "В данном контексте все эти метрики важны, так как мы хотим оценить, насколько хорошо модель предсказывает, понравится ли пользователю фильм.\n",
        "Precision важна, чтобы минимизировать количество ложных срабатываний (когда фильм предсказан как \"понравится\", но на самом деле не понравился).\n",
        "Recall важна, чтобы минимизировать количество пропущенных срабатываний (когда фильм на самом деле понравился, но модель не предсказала это).\n",
        "F1-score - это баланс между precision и recall"
      ],
      "metadata": {
        "id": "GIJ6Hx8yykrz"
      },
      "id": "GIJ6Hx8yykrz"
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_with_titles.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FepPzR30Vz0z",
        "outputId": "978efe89-8e41-4850-be45-57ff060c0581"
      },
      "id": "FepPzR30Vz0z",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_id', 'movie_id', 'liked', 'timestamp', 'release_date',\n",
              "       'movie_title', 'video_release_date', 'IMDb_URL', 'genre_0', 'genre_1',\n",
              "       'genre_2', 'genre_3', 'genre_4', 'genre_5', 'genre_6', 'genre_7',\n",
              "       'genre_8', 'genre_9', 'genre_10', 'genre_11', 'genre_12', 'genre_13',\n",
              "       'genre_14', 'genre_15', 'genre_16', 'genre_17', 'genre_18',\n",
              "       'release_year'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cxLv6uDZXS1R"
      },
      "id": "cxLv6uDZXS1R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost:** Градиентный бустинг хорошо справляется с задачами классификации, особенно на дисбалансных данных, благодаря возможностям настройки параметров и использования деревьев.\n",
        "1. Эффективность для табличных данных: XGBoost известен своей высокой точностью и эффективностью на табличных данных. Он способен хорошо работать даже на больших наборах данных, быстро обучаясь и обеспечивая высокое качество предсказаний.\n",
        "2. Устойчивость к переобучению: гиперпараметры, такие как max_depth=6 и subsample=0.8, регулируют сложность модели и ограничивают её, предотвращая переобучение.\n",
        "3. Параметры настройки:\n",
        "* n_estimators=100 — количество деревьев, используется для улучшения качества за\n",
        "счет усреднения предсказаний.\n",
        "* learning_rate=0.1 — скорость обучения, которая контролирует вклад каждого дерева в финальное предсказание.\n",
        "* subsample=0.8 и colsample_bytree=0.8 — эти параметры управляют, какая часть данных и признаков используется для каждого дерева, что повышает стабильность модели и снижает переобучение.\n",
        "* Параметр random_state=42 для воспроизводимости результатов."
      ],
      "metadata": {
        "id": "u5Ib_x78456Z"
      },
      "id": "u5Ib_x78456Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# Примерное использование SMOTE для балансировки классов\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Обучение модели XGBoost с оптимизированными гиперпараметрами\n",
        "model = XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train_balanced, y_train_balanced)\n",
        "\n",
        "# Предсказания и метрики\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue5e9lpnByUN",
        "outputId": "00b35098-c7bf-4c15-a5e3-9b88302d7c3b"
      },
      "id": "Ue5e9lpnByUN",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x7dbabaad0790>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
            "    self._make_controller_from_path(filepath)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 1175, in _make_controller_from_path\n",
            "    lib_controller = controller_class(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 114, in __init__\n",
            "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
            "  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "OSError: /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so: cannot open shared object file: No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7464\n",
            "Precision: 0.3719262295081967\n",
            "Recall: 0.28546712802768165\n",
            "F1-score: 0.3230112119594234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Мультиклассовая классификация\n",
        "# Превращаем оценки в мультиклассы: 1-5 звезды\n",
        "ratings_with_titles['rating'] = rating_mul\n",
        "X = ratings_with_titles.drop(columns=['liked', 'release_date', 'movie_title', 'video_release_date', 'IMDb_URL'])\n",
        "y_multiclass = ratings_with_titles['rating']\n",
        "\n",
        "X_train_mc, X_test_mc, y_train_mc, y_test_mc = train_test_split(X, y_multiclass, test_size=0.2, random_state=42)\n",
        "\n",
        "# Используем RandomForest для мультиклассовой классификации\n",
        "forest_mc = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "forest_mc.fit(X_train_mc, y_train_mc)  # Используем все данные без среза\n",
        "y_pred_forest_mc = forest_mc.predict(X_test_mc)\n",
        "\n",
        "print(\"\\nRandom Forest Multiclass Classification\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_mc, y_pred_forest_mc)}\")\n",
        "print(classification_report(y_test_mc, y_pred_forest_mc))\n",
        "onnx_model = convert_sklearn(forest_mc, initial_types=initial_type)\n",
        "\n",
        "# Сохраняем в файл\n",
        "with open(\"forest_mc.onnx\", \"wb\") as f:\n",
        "      f.write(onnx_model.SerializeToString())\n",
        "# 6. Мультилейбл классификация\n",
        "# Используем LabelBinarizer для преобразования мультилейблов\n",
        "lb = LabelBinarizer()\n",
        "y_multilabel = lb.fit_transform(ratings_with_titles['rating'])\n",
        "\n",
        "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(X, y_multilabel, test_size=0.2, random_state=42)\n",
        "\n",
        "# Используем RandomForest для мультилейбл классификации\n",
        "forest_ml = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "forest_ml.fit(X_train_ml, y_train_ml)\n",
        "y_pred_forest_ml = forest_ml.predict(X_test_ml)\n",
        "\n",
        "print(\"\\nRandom Forest Multilabel Classification\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_ml, y_pred_forest_ml)}\")\n",
        "print(classification_report(y_test_ml, y_pred_forest_ml, target_names=lb.classes_.astype(str)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkD-8HD5U4JE",
        "outputId": "6bde24bb-2385-4e31-cac8-45eac7da421e"
      },
      "id": "AkD-8HD5U4JE",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest Multiclass Classification\n",
            "Accuracy: 0.98725\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.81      0.90      1235\n",
            "           2       0.96      0.99      0.97      2233\n",
            "           3       0.97      1.00      0.99      5542\n",
            "           4       1.00      1.00      1.00      6792\n",
            "           5       1.00      1.00      1.00      4198\n",
            "\n",
            "    accuracy                           0.99     20000\n",
            "   macro avg       0.99      0.96      0.97     20000\n",
            "weighted avg       0.99      0.99      0.99     20000\n",
            "\n",
            "\n",
            "Random Forest Multilabel Classification\n",
            "Accuracy: 0.8927\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.08      0.16      1235\n",
            "           2       1.00      0.55      0.71      2233\n",
            "           3       1.00      1.00      1.00      5542\n",
            "           4       1.00      1.00      1.00      6792\n",
            "           5       1.00      1.00      1.00      4198\n",
            "\n",
            "   micro avg       1.00      0.89      0.94     20000\n",
            "   macro avg       1.00      0.73      0.77     20000\n",
            "weighted avg       1.00      0.89      0.92     20000\n",
            " samples avg       0.89      0.89      0.89     20000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Анализ результатов\n",
        "\n",
        "Из предоставленных результатов можно сделать выводы, что для каждых из алгоритмов имеются разные показатели качества классификации, особенно в разрезе задач бинарной, мультиклассовой и мультилейбловой классификаций.\n",
        "\n",
        "#### Бинарная классификация (предсказание, понравился ли фильм на основе рейтинга)\n",
        "1. **Logistic Regression:**\n",
        "   - Точность (Accuracy): 0.788\n",
        "   - ROC AUC: 0.496 — что указывает на почти случайное предсказание для классов\n",
        "   - Recall для класса 1 (рейтинг 5, который считается \"нравится\"): 0.0, что означает, что модель не смогла корректно предсказать ни одного примера класса \"нравится\".\n",
        "\n",
        "2. **Random Forest:**\n",
        "   - Точность (Accuracy): 0.790\n",
        "   - ROC AUC: 0.681 — показывает более выраженную способность отличать классы.\n",
        "   - Precision и Recall для класса 1 выше, чем у Logistic Regression, но Recall остаётся низким (0.03), что указывает на проблему с предсказанием положительных примеров.\n",
        "\n",
        "3. **Decision Tree:**\n",
        "   - Точность (Accuracy): 0.791\n",
        "   - ROC AUC: 0.634 — показывает, что модель немного лучше справляется с классификацией, чем Logistic Regression.\n",
        "   - Значения Precision и Recall схожи с Random Forest, но по-прежнему Recall для класса 1 остаётся низким.\n",
        "\n",
        "4. **XGBoost:**\n",
        "   - Точность (Accuracy): 0.793\n",
        "   - ROC AUC: 0.702 — модель лучше справляется с разделением классов, чем предыдущие, но также имеет сложности с предсказанием класса 1.\n",
        "   - Precision и Recall для класса 1 также улучшились, но общий эффект незначителен.\n",
        "\n",
        "**Вывод по бинарной классификации**: **XGBoost** показывает лучшие результаты по метрикам ROC AUC и точности, а также по общей предсказательной способности для класса 1, но для улучшения recall потребуется дальнейшая работа с дисбалансом классов.\n",
        "\n",
        "#### Мультиклассовая классификация (оценка фильмов в категориях от 1 до 5)\n",
        "1. **Random Forest**:\n",
        "   - Точность (Accuracy): 0.987\n",
        "   - F1-score по каждому классу показывает высокие значения (близкие к 1.0), особенно для высоких оценок (классы 4 и 5).\n",
        "   - Более низкий Recall наблюдается для класса 1 (рейтинг 1), но в целом модель отлично справляется с различением всех классов.\n",
        "\n",
        "**Вывод по мультиклассовой классификации**: **Random Forest** продемонстрировал отличные результаты с точностью почти 0.99 и хорошо сбалансированными значениями F1-score для всех классов. Это делает его отличным выбором для мультиклассовой задачи предсказания оценки.\n",
        "\n",
        "#### Мультилейбловая классификация\n",
        "1. **Random Forest (мультилейбл)**:\n",
        "   - Точность (Accuracy): 0.893\n",
        "   - Микро- и макро-значения Recall и Precision достаточно высоки, хотя Recall для класса 1 остаётся низким.\n",
        "   - Средние значения Precision и Recall показывают, что модель хорошо обрабатывает многометочные задачи, но могут быть проблемы с классом 1.\n",
        "\n",
        "**Вывод по мультилейбловой классификации**: Для задач, где нужны предсказания для нескольких меток одновременно, **Random Forest** также показывает хорошие результаты и высокую точность, но проблема с классовым дисбалансом всё ещё остаётся.\n",
        "\n",
        "### Заключение и\n",
        "\n",
        "1. **Для бинарной классификации** наилучшие результаты показал **XGBoost** с высоким значением ROC AUC и общей точностью. Однако низкий Recall для класса 1 указывает на необходимость улучшения предсказания редких классов (например, применением методов балансировки классов).\n",
        "\n",
        "2. **Для мультиклассовой классификации** **Random Forest** демонстрирует отличную точность и сбалансированность метрик, и его стоит использовать в этом типе задачи.\n",
        "\n",
        "3. **Для мультилейбловой классификации** также **Random Forest** является лучшим вариантом. Но для задач, где важен каждый класс, стоит рассмотреть методы балансировки данных или перераспределения весов.\n",
        "\n",
        "Таким образом, **XGBoost** наиболее подходит для бинарной задачи, а **Random Forest** для мультиклассовой и мультилейбловой классификации, обеспечивая высокую точность и хорошие значения Precision и Recall."
      ],
      "metadata": {
        "id": "Iddrw41z8SIa"
      },
      "id": "Iddrw41z8SIa"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}